<!doctype html>
<!--[if IE 9]>
<html class="lt-ie10" lang="en"> <![endif]-->
<html class="no-js" lang="en" data-useragent="Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Trident/6.0)">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Kafka Java Client</title>
        <meta name="description" content="Gérald's technical blog about Java, Kafka, Elasticsearch, DevOps...">
        <meta name="author" content="Gérald Quintana">
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="/css/coderay.css">
        <link rel="stylesheet" href="/css/asciidoc2.css">
        <link rel="stylesheet"
              href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/default.min.css">
    </head>
    <body>
        <header class="container sticky-top">
            <nav class="navbar navbar-expand-md navbar-dark bg-dark">
                 <a class="navbar-brand" href="/"><h1>JRald blog</h1></a>
                 <h2>
                     <a href="https://twitter.com/gerald_quintana"><i class="fa fa-twitter"></i></a>
                     <a href="https://github.com/gquintana"><i class="fa fa-github"></i></a>
                     <a href="/feed.xml"><i class="fa fa-rss"></i></a>
                 </h2>
            </nav>
        </header>
        <main class="container position-relative " role="main">
            <div>
    <h1>Kafka Java Client</h1>
    <div>
        <img class="rounded float-right" src="../../../images/logos/kafka.png"/>
        <h5>
            <span>2016-10-10</span>
            <span class="badge badge-secondary">kafka</span> <span class="badge badge-secondary">java</span> 
        </h5>

        <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Apache Kafka is trendy software which mixes a message broker and an event log.
From the ground up, it&#8217;s a distributed solution designed for scalability and performance.
It was created by LinkedIn in 2011, it is now open-source and supported by the Confluent company.</p>
</div>
<div class="paragraph">
<p>For Java developers, until Kafka 0.8, there was only an intricate Scala API with Java bindings.
Since 0.9 there is a pure Java API which makes things simpler.
In this blog post we will discuss this API.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="creating_a_topic">Creating a Topic</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The <strong>topic</strong> is the place where messages are sent and where they are stored.
All messages send to Kafka are written to disk.</p>
</div>
<div class="paragraph">
<p>A topic is split into multiple <strong>partitions</strong>.
Each partition is usually placed on a different Kafka node.
Each partition can be <strong>replicated</strong> many times in order to tolerate node failures.
Among replicas, a leader is elected, it has the privilege of receiving messages first and sending messages to consumers.</p>
</div>
<div class="paragraph">
<p>A topic is automatically created when the first message arrives.
Alternatively, it may be manually created with the <code>kafka-topic.sh</code> command line tool:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic newtopic --partitions 5 --replication-factor 2
Created topic &quot;newtopic&quot;.
$ bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic newtopic
Topic:newtopic  PartitionCount:5        ReplicationFactor:2     Configs:
        Topic: newtopic Partition: 0    Leader: 2       Replicas: 2,3   Isr: 2,3
        Topic: newtopic Partition: 1    Leader: 3       Replicas: 3,1   Isr: 3,1
        Topic: newtopic Partition: 2    Leader: 1       Replicas: 1,2   Isr: 1,2
        Topic: newtopic Partition: 3    Leader: 2       Replicas: 2,1   Isr: 2,1
        Topic: newtopic Partition: 4    Leader: 3       Replicas: 3,2   Isr: 3,2</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the topic has five partitions.
Partition 0 has two replicas: one on node 2, the other node 3.
The replica on node 2 is the leader.
You will notice the leader partitions are evenly distributed among this 3 node cluster.</p>
</div>
<div class="paragraph">
<p>Each partition is an independent log of events.
In this log, messages are <strong>sorted</strong> by their arrival order.
Each message is identified by its position in the log, this position is called <strong>offset</strong>.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="2016-10-10-Kafka-Java-Client/kafka_topic.svg" alt="Topic" width="Partitions and Offsets">
</div>
</div>
<div class="paragraph">
<p>At the time of writing (Kafka 0.10.0), it is not possible to create or delete a Topic with the Kafka Client library.
By the way, this should change in the upcoming release (0.10.1).
Right now, you&#8217;ll have to stick with the forementioned command line tool, or use the Scala library which contains an <code>AdminUtils</code> class.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="message_record">Message / Record</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A message is also called a <strong>record</strong> in the Kafka vocabulary.
It consists of:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>An optional <strong>key</strong>: it doesn&#8217;t guarantee message uniqueness, multiple messages may have the same key.</p>
</li>
<li>
<p>A <strong>value</strong>: the body, the main part of the message</p>
</li>
<li>
<p>A <strong>timestamp</strong> (since Kafka 0.10): when the message was created by the producer or recorded in the broker</p>
</li>
<li>
<p>An <strong>offset</strong>: a big number describing the position of the message in the log</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the key is provided, it is hashed and this hash is used to determine in which partition it should go.
Two messages with the same key will end in the same partition.
Messages having the same key can be merged together by an optional background process called compaction.</p>
</div>
<div class="paragraph">
<p>The key and the value can be of any type: <code>String</code>, <code>long</code>, <code>byte[]</code>&#8230;&#8203;
This is made possible by <strong>serializers</strong> and <strong>deserializers</strong> which are strategies to read and write anything from byte stream.
Some (de)serializers are provided for basic types,
and there are some third party (de)serializers to handle complex types.
For example, it&#8217;s possible to exchange plain objects written in <a href="https://github.com/confluentinc/schema-registry/tree/master/json-serializer">JSON</a> or Avro format.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sending_messages">Sending messages</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Messages are sent to the Kafka broker using a <strong>producer</strong>.
The producer knows the distribution of topic partitions on nodes,
it will hash the record key and send the record directly to the appropriate partition/node.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="2016-10-10-Kafka-Java-Client/kafka_producer.svg" alt="Producer">
</div>
</div>
<div class="paragraph">
<p>When no key is provided, the producer uses a random partition.
In short, the producer is able to load balance writes to all partitions, and associated nodes.</p>
</div>
<div class="paragraph">
<p>This producer is initialized and configured with some properties.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Object</span>&gt; producerConfig = <span class="keyword">new</span> <span class="predefined-type">HashMap</span>&lt;&gt;();
producerConfig.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">kafka1:9092,kafka2:9092</span><span class="delimiter">&quot;</span></span>); <i class="conum" data-value="1"></i><b>(1)</b>
producerConfig.put(ProducerConfig.ACKS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">1</span><span class="delimiter">&quot;</span></span>); <i class="conum" data-value="5"></i><b>(5)</b>
producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class); <i class="conum" data-value="4"></i><b>(4)</b>
producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
<span class="keyword">try</span> (Producer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(producerConfig)) {
    ProducerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string"><span class="delimiter">&quot;</span><span class="content">the_topic</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">the_key</span><span class="delimiter">&quot;</span></span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">The Message</span><span class="delimiter">&quot;</span></span>); <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="predefined-type">Future</span>&lt;RecordMetadata&gt; futureMetadata = producer.send(record);<i class="conum" data-value="3"></i><b>(3)</b>
    RecordMetadata metadata = producer.get(); <i class="conum" data-value="5"></i><b>(5)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Connect to these Kafka connect nodes.
The first Kafka node to answer will give the full list of nodes.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Create the record/message</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Send the message.
By default, this operation is asynchronous and non blocking, it immediately returns a <code>Future</code></td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The message and the key are written on the wire using the string serializer.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Wait for message acknowledgement.
The <strong>Acks</strong> config indicates how many replicas should write the message to disk before returning an acknowledgement to the producer.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In a real world application, the producer should be instanciated only once and reused for the application lifespan.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="receiving_messages">Receiving messages</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Messages are received from the Kafka broker by a <strong>consumer</strong>.
A consumer is a process in charge for reading messages from a topic and dealing with them.
As an acknowledgement, the consumer writes the message offset back to the broker, it&#8217;s called <strong>offset commit</strong>.</p>
</div>
<div class="paragraph">
<p>A <strong>consumer group</strong> is a set of consumers distributed on multiple machines.
For a given topic and group, each partition gets read by a single consumer.
This prevents messages from being consumed twice in the consumer group.
On the contrary, a consumer can be in charge of several partitions.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="2016-10-10-Kafka-Java-Client/kafka_consumer.svg" alt="Consumer and Consumer Group">
</div>
</div>
<div class="paragraph">
<p>The Kafka cluster tells each consumer which partition it should read from.
Each consumer takes care of its portion of topic.
As a result, consumers can work independently and in parallel,
and messages stored in a topic can be load balanced to consumers on many machines.
In case of consumer failure, Kafka reassigns the partitions to other consumers of the same group.</p>
</div>
<div class="paragraph">
<p>Like the producer, the consumer is initialized and configured with some properties.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Object</span>&gt; consumerConfig = <span class="keyword">new</span> <span class="predefined-type">HashMap</span>&lt;&gt;();
consumerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">kafka1:9092,kafka2:9092</span><span class="delimiter">&quot;</span></span>); <i class="conum" data-value="1"></i><b>(1)</b>
consumerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">test_group</span><span class="delimiter">&quot;</span></span>);
consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
<span class="keyword">try</span> (Consumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(consumerConfig)) {
    consumer.subscribe(<span class="predefined-type">Arrays</span>.asList(<span class="string"><span class="delimiter">&quot;</span><span class="content">the_topic</span><span class="delimiter">&quot;</span></span>)); <i class="conum" data-value="2"></i><b>(2)</b>
    ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="integer">1000L</span>); <i class="conum" data-value="3"></i><b>(3)</b>
    <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records) {
        LOGGER.info(<span class="string"><span class="delimiter">&quot;</span><span class="content">Found message {} {}</span><span class="delimiter">&quot;</span></span>, record.key(), record.value());
    } <i class="conum" data-value="4"></i><b>(4)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Connect to these Kafka connect nodes.
Like the producer, it doesn&#8217;t have to be the whole Kafka cluster.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Register this application (consumer group) as a consumer for this list of topics.
In return, Kafka will assign some partitions to this consumer.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Try to pull messages from the broker.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Pulled messages are automatically acknowledged.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In the above example, connecting to the broker, subscribing to one or more topics,
and being assigned partitions takes time and is usually done once during application start-up.
On the contrary, the <code>poll</code> method should be run in loop.
It returns a batch of records whose size is controlled by the <code>max.poll.records</code> and <code>max.partition.fetch.bytes</code> settings.</p>
</div>
<div class="paragraph">
<p>Unlike the producer, the consumer is not thread-safe.
In order to consume records in parallel, each thread should have it&#8217;s own consumer.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="acknowledging_received_messages">Acknowledging received messages</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The message acknowledgement is called <strong>offset commit</strong>,
because Kafka keeps track of the offset of the last consumed message for each topic + partition + consumer group.</p>
</div>
<div class="paragraph">
<p>In the previous example, the offsets were automatically and periodically committed to the broker.
This auto commit is configurable through properties:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">consumerConfig.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="predefined-constant">true</span>);
consumerConfig.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="integer">1000L</span>);
<span class="keyword">try</span> (Consumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(consumerConfig)) {
    consumer.subscribe(<span class="predefined-type">Arrays</span>.asList(<span class="string"><span class="delimiter">&quot;</span><span class="content">the_topic</span><span class="delimiter">&quot;</span></span>));
    ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="integer">1000L</span>);
    <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records) {
        LOGGER.info(<span class="string"><span class="delimiter">&quot;</span><span class="content">Found message {} {}</span><span class="delimiter">&quot;</span></span>, record.key(), record.value());
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>This offset commit can also be manual in order to ensure messages are acknowledged once they have been processed.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">consumerConfig.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="predefined-constant">false</span>);
<span class="keyword">try</span> (Consumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(consumerConfig)) {
    consumer.subscribe(<span class="predefined-type">Arrays</span>.asList(<span class="string"><span class="delimiter">&quot;</span><span class="content">the_topic</span><span class="delimiter">&quot;</span></span>));
    ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="integer">1000L</span>);
    <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records) {
        LOGGER.info(<span class="string"><span class="delimiter">&quot;</span><span class="content">Found message {} {}</span><span class="delimiter">&quot;</span></span>, record.key(), record.value());
    }
    consumer.commitSync();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>This offset can even be moved forward (to skip records) and backward (to replay records):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">    consumer.seekToBeginning(consumer.assignment());</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="using_a_framework">Using a framework</h2>
<div class="sectionbody">
<div class="paragraph">
<p>You may have noticed that the consumer API is a pull API.
In a real application you&#8217;ll have to create a consuming loop in separate thread,
and build a push API.</p>
</div>
<div class="paragraph">
<p>The <a href="http://docs.spring.io/spring-kafka/docs/current/reference/html/">Spring Kafka</a> does all the heavy lifting for you
and smoothly integrates Kafka with Spring and Spring Integration:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The <code>KafkaTemplate</code> can send messages</p>
</li>
<li>
<p>The <code>KafkaListener</code> can receive message in a push manner</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This library makes Kafka usage very similar to ActiveMQ or RabbitMQ.</p>
</div>
</div>
</div>
    </div>
    <div class="clearfix">
        <h4>Other posts</h4>
        <ul>
            
                <li>2020-11-28
                    <a href="/2020/11/28/Build-your-own-CA-with-Ansible.html">Build your own CA with Ansible</a>
                </li>
            
                <li>2020-01-16
                    <a href="/2020/01/16/Retrieving-Kafka-lag.html">Retrieving Kafka Lag</a>
                </li>
            
                <li>2020-01-10
                    <a href="/2020/01/10/Home-temperature-monitoring.html">Home temperature monitoring</a>
                </li>
            
                <li>2019-12-10
                    <a href="/2019/12/10/Kafka-connect-plugin-install.html">Kafka connect plugin install</a>
                </li>
            
                <li>2019-07-03
                    <a href="/2019/07/03/Kafka-integration-tests.html">Kafka integration tests</a>
                </li>
            
        </ul>
    </div>
</div>

        </main>
        <footer class="footer text-muted">
            <div class="container">
                <p class="float-right">
                    <a href="#"><i class="fa fa-arrow-up" aria-hidden="true"></i>
 Back to top</a>
                </p>
                <p>Made with <i class="fa fa-heart" aria-hidden="true"></i> by Gérald Quintana</p>
        </footer>
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
    </body>
</html>
